{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 10:\n",
      "Image - Min Value: 42 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 7 Name: horse\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAGjxJREFUeJzt3VvPXdd5HeC59uk78SMpRqJEUpIlWxbkynZcqbVjB01T\ntw5QICmKoOhP7B8oEKCXBQwUTY3aaaJIsmTZOouWSInkd9rH1QvfqJdzlKacF89z/+Lde62519jr\nagzjODYAoKbJV/0BAIDfH0EPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6\nAChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoLDZV/0Bfl9+fvuzMZmb7R10z2zbNlnVprtp98xu\niFa1cYwuR4vGhmzXMOmfG8Lr0bKPGH21RXY8WvLVhviC9EvP1D8FyXV8lNc+lT4/JsHg0HbRrlXw\nHGittfHBWffM5GA/2jWc9u/au3Il2vX8Y0f/3wfLGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0BhZdvr9hf9LXSttbbYO+ye2Q1ZS9N0099eNz7i\ntrZH2k8WfLc//L6w1qbxh+y/+mmjXNTWFl79tPQua1LMdk2i6sBs16OUvtlNgkfcOl22vYjG3n79\nf3XPfO1bL0a7Pnr9190zL/3gT6JdD4M3egAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhQl6AChM0ANAYYIeAAoT9ABQWNlSm0lbh3Ob7plx3Ga7wjKcxBA2qyRlJ3GBTtp28gglpUJjcg1T\n6apHWeIS3udx1/97ic5ve8T3LJZ8xuxZFa2aZO+Ri+VJNDd5/43umXc++kW26/hm98xw0F9i9rB4\noweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6ACis\nbHvdbDLP5ob+uemQ/V+aBXPj8Iff8BZ7hI1h+aY/8Faz8Hgkx2qYPMqqvLRRLmyIDGoKh6TasLU2\npDctMAk/Y3LLphdn0ar3fvrTaO7eG693z1x76evRrqPj4/6h9TLa1Q4Os7kv8UYPAIUJegAoTNAD\nQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAorW2ozGbIyi2kyF+6aDdPu\nmd0j/ms27pK2k2zXo6yLGcICnWisaA9R2OUU3+fkMu622a7Vun9wEl6QxTS7ItG25PfcWpvN+7e9\n9+Yb0a6//W9/E81dnvQ/h68/9US06/T8pHvm47ez63HjlVeiuS/zRg8AhQl6AChM0ANAYYIeAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFBY3fa6sDIsKZJKy8lmya5J1nQ1\nhh8y2Ze2k0Vz6cVPG/YeZcVe4hF+vvRMxfuCJrrT+xfRrtW6/8ull346ZBV7RweL/plFf2Nma63t\nBxf/3gfvRrs++/TTaO7g6RvdMx+9mzXKnV70R+c3vv5StOth8EYPAIUJegAoTNADQGGCHgAKE/QA\nUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQWNn2unGd/YfZDI+ukms72XXPTPay\njqxJ2K2VXI3032N26bP7lTavJVcx3hVU5aXHN7v02bLtNps7e7Dqnrn/+Vm0azHpfzROduto127o\n/16ttXZ0dLV7Zj+tezw97R452iyjVWcP+ne11tqnF5vumfVv70a7xmV/c+C35nvRrofBGz0AFCbo\nAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxsqc3FWVaocHGy\n7Z7ZhkURxwf73TOH03m0azqdRnObbX/xzia8HrPgM+7WYUHKaVZ20oKimWl4z/b2++dms6y8KJnq\n/6X8zjjJPmPS2DOus6KZvUn/3N6s/7fSWmuXrx5Gc0fBvu35SbRr8+CL7pnZMiunOT/LPuPPfvH3\n3TM//tEfR7uee+qp7pntp1mBTvtWNvZl3ugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKK9te9+DuJ9Hc9qy/IWs9XUS7jp59vntm3GUtdOtN1qx1\ndnLePbPdZM1wk21/4+D55w+iXQ++yBqyDq9c7Z7Zu3wl2jVcvtQ9s7icNaFNgifBMGYtdGPYbng4\n7e/LG+ZZe93+sv9cjeMm2rW3uBXNbS/6fy8fv/1WtOv8k/e7Zz59981o13yRXcd56382PnPjiWjX\nwWP9P5iTzz+Odj0M3ugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJ\negAoTNADQGFlS23uf/JRNDee9xcqzA4Pol2rK8fdM/MxKy2593F2PT58+5fdM7fffSPa9cXt97pn\nxmV/0UlrrU2TFpfW2v7ly90zf3TjqWjXsNjvnlmHRTOT+V73zHzM3hPWq/4yltZa260uumcOsy6n\nNh/6P+PBE1l50XcP5tHcg7t3umfe/NufRrvOb/eX2ty7kz1zDvez4q6/+PN/2z1ztsju2cV5/8G6\nfpw9qx4Gb/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugB\noDBBDwCFlW2vW53dj+bmSbPW5EG0685bd7tnTqdjtOvjt96M5u5/9GH3zOmd30a7Zrv+5sDFZBHt\n2g7Zf9z5tP987H+WtVYNwf/wzz/5NNp1etb/vXbhe8IquM+ttbbdBNe+ZW1+bexvyrv01OPRqmF9\nFs2dP7jXPfPBa38X7Tqc9D931pvs3F+7/mQ490T3zIOz7Cwuz/rv2Y2bWUvhw+CNHgAKE/QAUJig\nB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoLCy7XUvvPhcNHd5\nuuueGYZVtKut190j7/0ya6FbhHf6qZs3u2cu7e9Fu07u9bf53fn0TrZrmd2za/v9DVTDfnbx96bT\n7plLB9Gq1i7Ou0eW6/7fSmutbdbh72XsbxqbTbN3maO9/vs8XpxGu975+59Hc7tVf8PeXssa5Q72\nDrtnhkuXo10vv/qDaO6Zl7/XPTNsszO82/Wf4cOj/na9h8UbPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGypzfFxVqxyOPTPzO7fi3aNl/o/4/5edsuO\njq5Ec9vtonvmcJUVZ9y5/VH3zL0Hn0e7tmP2GbcX/a0xB/vZ/+lx3V/iMkyyko71btk9c36Wlbhs\nN/3fq7XWxqCQZTjaj3ZdffKp7pnL1/4o2nW+7C+naa2105P+e73cZLvadOweOXz8WrTq66/0l9O0\n1trVy0lpTPYcaK0/KCaz7Cw+DN7oAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugB\noDBBDwCFCXoAKEzQA0Bhgh4ACivbXjes19HcNpibPMhavMZF/+W/CJvyNmeraG69629cWsyz/4+r\ndX+zVjLTWmt7wbVvrbVp629eW56dhLv6G7LWq+x6XFycd89st1kL3TBkDXvbTf9vc5Ud+9Zm/df+\n6LHL0ar5Kms12z8+6p45uZe1et7+4IPumSdvPB3tmh/0N2a21tpy2f8c3rUsJ8b+Mr823csO43E0\n9f/yRg8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4ACitb\najPv76T4naAkZTLJLuM4zLtn7t7+ONr14JM70dytr7/cPXOxzIpVzs6CUopdVqwynfVf+9ZaOzo6\n6J7ZjVlxxnrV/902m2W0a7XqL7UZk2aP1towZHNjUCg0X2SFMUOwax1cw9ZaOzzKynDGZX9JSv/p\n/Z3L5/3n6uhK9r1mYSlWu+i/Z2PLimZ2wRGejNNo18PgjR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEP\nAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwsu11m7aN5qZBa9UibGnaBM1am/OsIev0\n89vZ3P0nu2c+eP/daNeDky+6Z4ZhF+2azbJ6w8ce67/Xy4uzaNfyrL8FcDdm5z5plFuFTXnT8PUi\n+YxXrhxHu2at/1wNYWvj5OBSNDcGxY0XQcNba60Ni73umWvXn4h2bTZZo1zb9J/9MTyLSWPpMGiv\nAwB+DwQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhZUttdlt\ns9KSyWrdPbOZz6Ndu73D7pm9S1mBznqZleH89vbH3TPvfdg/01prm21QyHIpKy352is/iOZWs/6f\nzG9++Xq0a976z/DqNLvPy6Ab6DwoEWmttd2u/zfWWmuLWX8pyNlFVjRzdPqgf9f8INp174us9Ogi\n+L18fh7es2n/ub9249lo17B7dOUvk12WE+PQfz3GTbbrYfBGDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrtaozmVl/c7545WOxHuxZBe92t\n51+Idt351ZvR3GnQ/jVOFtGuk1V/u9Mf//D70a4//w//OZpbrzfdM7defCna9dbrb3TPfPLeB9Gu\n7aT/DC+Or0a7lmGT4tlF/9yv7/a30LXW2nLS36B2PMm+1/q0/5nTWmtHh/2tmYeP3Yp2vfDKD7tn\nLt/Idu02/b+x1lqbtP57lvbkJR2AQ9BG+bB4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAK\nE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6ACisbHvdMMmagoahfy7ryWttGwweX7se7ZofZU1j473+\n9q/FwUG064Xn/mX3zE/+8q+jXYu9o2huHhTzfeM7r0a7nnvpu90zq/P+tsHWWlsGc2PbRbvWq2U0\nd3F+2j2zPDuJdk2C58BkyB6nH/7if0Zzy5M73TPXvpY1yj397W92z6zD8zEd0ydqv/VmHc1tt/3v\nyNOv8L3aGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoA\nKKxsqU3aNDOdTrtnJtPs/9JkNu+e2c32ol3j3qVobrO+2z3z2ONZgc6/+qu/7J45DHetlqtobhb8\nNx430ao2nfT/PA+OjqNdydwYFkdNwrlpUJIyCYtVdkNwn5fZjT5/761o7rX33+2eOcw6XNoQXI9d\n+BtLy1+2wbEad9n52CQBs91Gux4Gb/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFlW2vm4WNcrtZfwXSxelptOvaor+JbrXJGrKOj4+iuXsHh90z\n33z1X0S7rt96qnvm7Dy79tOw3nC36Z+bD4to13bs3zWGf92H4NwPm6yFbhs2hq03/dVrw5jt2gbN\ngYshfZxmN20d3Oxd62/nbK21WXAZ1+usrW2cZudqF1zGSfAba621aZAvw+Sre6/2Rg8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4ACitbajPuskKFpNxjs1pF\nu9quv1BhGPuLPVpr7eT+nWju6jPPdM88/53vRbuGpDAmbHHZbsPCjdZ/PrbBTGut7YJClmEIy3qC\noplhfLQlLuNk3j8Tlhcl93mzzQp0pvv70dzhlUvdM8M0ux6tJb+X7DeWPBd/ty54ngZFSa21NiQ/\n6TG8Hg+BN3oAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QA\nUJigB4DCyrbXbcMGpNk8aJLanEe72kV/691um/03Owlb3r798re7Z+YHWRvXdr3pnwlb6FJDUFt1\nvj2Ndi2m0/6hZdjKFzSvLSdZ89cuqv5qbT7rf1yNY/YcmASXfgzb2g7D38u46b+O64v+31hrrU2j\n5rXwGRzOrXb9322YZhE4DX6b4bF/KLzRA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAo\nTNADQGGCHgAKE/QAUJigB4DCBD0AFFa2va4N2X+Y6eKge2Y8z9rrNhf9c1eeuBntevlP/iyau37z\nVvfM8vQi2jWfPbr/nWmr2Rg0a41ha9W29Q9u1mFbW/CffxrervkkvPab/rbHcexv5WuttdWu/9G4\nWWXfazfZi+bun/e3B55/di/a9do7t7tndkEbZWutjZtsbr3rv9dD2H65G/rv9fGVS9Gu7z//SjT3\nZd7oAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0BhZUtt\nluv+wofWWpsFTR178+wyrpb9pTZ7V69Gu27OXozmtif9n3Fc95ePtNbaNvjfOUym0a71Jis7Ob9Y\nds/89s4X0a7bn93tnvni/mm0ax10e9w/OYt2LVfZ+ZjN+n9nu7C0ZL3tPx8XJyfRrhevZmf409P+\ne/2P/+Nn0a7//vqH3TNpYUwL524+faN75tbjj0W7/s8//F33zLdffina9f0f/8do7su80QNAYYIe\nAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABRWtr1uO26i\nuV3w32c9ZP+Xxjufds/Mnn422rVYHEZzm1l/k9QwzZrhVtv+VrMPPrwd7frHt96L5t55v3/fR3fu\nR7u+uPege2YTNn+t1v2/l+12jHbtdtn5mC8W3TOTSfgus+k/ixdBm1xrrT3741ejuVu3numeee2z\nX0W7fnu3v4HxuSeyZriXv/lCNPen//oH3TM3HsvaQC8d9jcOXjq+FO16GLzRA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCypbatCEbW6+DEpdZf9lGa62t\n793rnjm4OIl2DW0vmtuM/Rfyndt3o10/f+2X3TM/+9//EO36+NP+ko7WWjtb9p+Pg6Ps2h8f9J+r\n55++Hu26/nh/Acn+PPte201WODWd9j+uDg72o11D8PxYrvqLcFpr7Uff+0Y0d+/j33TPvH+2jnad\nT466Z/7Tv/9JtOu5W9kZnga3ep7c6NbaX/y7P+uemc6/urj1Rg8AhQl6AChM0ANAYYIeAAoT9ABQ\nmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFBY2fa6YczmpsO8f2Y/a69rJ6fdI7uw\nvW56cBDN/er9j7pn/st//Zto17sffdY9c/nScbTrmZtPR3MvfOP57pnrT/Q3f7XW2uNX+udeePZG\ntOvSQf+5H3ZZ89dkOo3mZrP+x9Vkkr3LrLf9DXvbIXucHgzn0dylvf6H3F9/7VvRrklQDXfz2tVs\n19jfENlaa5ugFXEb5sR80n/258H5fVi80QNAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoA\nKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABRWt70unJtP+5vopgd70a7Dy/3tZKcX/Y13rbW2nmQtb2//\n+v3umQ8++DDa9erL/6x75t/86Y+iXVfDe/bUE9f6h6a7aNcQHOKhZXVcydw2fHrsdtln3I391zF9\nDrQx+IyTrJXvfBmNtcXlJ7tnDlt27me7/ma46Bq21jZho9wqKL2bjtm77mLW3wY6+Qrfq73RA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCypbazBfzaG66\n7W9U2E2y6ozdXv9nXH1+J9p1dn47mpsGhSz//OUXol1/9ZMfds88/+zT0a5xs4rm2thf7rHZBm0b\nrbVx7D9XwywrVmlD/6NgF5aWDLPs97Le9F/7MfxtTuf95VbbdVD80lobgiKt1lp77ze/6Z55/+NP\nol2vfu87/UPh99ql1zGY2UyznJhP+t+Rh3DXw+CNHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6\nAChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoLCy7XXrdX/rWmutjUHT2HietS3N9q91z2xXD6Jd\n97/4LJq7frDXPXPzu9+Ndj39xJP9Q5vwPo9Zy9tu279vSP9PJ+1w63DVEJz7bXbu49a7oJ9sEl77\n7ba/3XA+ZLsm4dwLT/c3Nz5/82a0azoN2g0vssO4mGa/zdWyf99kHjblBY+dMRl6SLzRA0Bhgh4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCypbanAQlHa211qb9\nxRnb5Vm06nzsL4y5O5lHux70f63WWms3nu8vzjg6vhTtupj2/+9cB0UnrbW23WUFE6t1f3HG3n7/\nfW6ttWEIvlvWF9M2QUHNZpIt2+2y3+YYlfxkxSqT4Fwt5tlvM7nNrbU2W/TvW6+zEpeToDAmKSFq\nrbX5JCwHmvfH2Wq7jHaNLSg92mXPgYfBGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAH\ngMIEPQAUJugBoDBBDwCFCXoAKEzQA0BhQ9QIBQD8k+CNHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeA\nwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIX9X2vzXBeiIamsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24f4b90b5c0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 10\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    a=0\n",
    "    b=255\n",
    "        \n",
    "    return (x-a)/(b-a)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import preprocessing\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #labels = np.array(x).reshape((-1,1))\n",
    "    #lb = preprocessing.LabelBinarizer()\n",
    "    #lb.fit([0,1,2,3,4,5,6,7,8,9]) \n",
    "    #return lb.transform(labels)\n",
    "    result = np.zeros((len(x), 10))\n",
    "    for i in range(len(x)):\n",
    "        result[i,x[i]] = 1\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.54901961,  0.49019608,  0.45098039],\n",
       "         [ 0.57254902,  0.50980392,  0.47843137],\n",
       "         [ 0.56078431,  0.49803922,  0.47843137],\n",
       "         ..., \n",
       "         [ 0.66666667,  0.56862745,  0.51372549],\n",
       "         [ 0.69019608,  0.58823529,  0.5254902 ],\n",
       "         [ 0.66666667,  0.57647059,  0.52156863]],\n",
       "\n",
       "        [[ 0.4745098 ,  0.42352941,  0.50588235],\n",
       "         [ 0.50980392,  0.4627451 ,  0.54509804],\n",
       "         [ 0.5254902 ,  0.4745098 ,  0.56078431],\n",
       "         ..., \n",
       "         [ 0.63921569,  0.55294118,  0.61568627],\n",
       "         [ 0.66666667,  0.57254902,  0.63137255],\n",
       "         [ 0.66666667,  0.58039216,  0.63137255]],\n",
       "\n",
       "        [[ 0.59607843,  0.54509804,  0.68235294],\n",
       "         [ 0.61568627,  0.56862745,  0.70196078],\n",
       "         [ 0.60784314,  0.56078431,  0.68627451],\n",
       "         ..., \n",
       "         [ 0.69411765,  0.60392157,  0.75686275],\n",
       "         [ 0.70980392,  0.61176471,  0.76078431],\n",
       "         [ 0.71764706,  0.62745098,  0.76078431]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.49019608,  0.43137255,  0.4       ],\n",
       "         [ 0.50588235,  0.43921569,  0.40392157],\n",
       "         [ 0.29803922,  0.2627451 ,  0.18431373],\n",
       "         ..., \n",
       "         [ 0.65882353,  0.5372549 ,  0.47058824],\n",
       "         [ 0.61960784,  0.49411765,  0.40392157],\n",
       "         [ 0.57254902,  0.45490196,  0.34117647]],\n",
       "\n",
       "        [[ 0.33333333,  0.30196078,  0.2745098 ],\n",
       "         [ 0.36862745,  0.31764706,  0.27843137],\n",
       "         [ 0.29019608,  0.25490196,  0.17647059],\n",
       "         ..., \n",
       "         [ 0.63529412,  0.51764706,  0.41568627],\n",
       "         [ 0.65098039,  0.5254902 ,  0.39215686],\n",
       "         [ 0.61960784,  0.50196078,  0.36078431]],\n",
       "\n",
       "        [[ 0.49019608,  0.43921569,  0.43529412],\n",
       "         [ 0.50980392,  0.44313725,  0.43529412],\n",
       "         [ 0.41176471,  0.35686275,  0.29411765],\n",
       "         ..., \n",
       "         [ 0.51764706,  0.41568627,  0.30588235],\n",
       "         [ 0.50980392,  0.39607843,  0.25098039],\n",
       "         [ 0.55686275,  0.45098039,  0.30588235]]],\n",
       "\n",
       "\n",
       "       [[[ 0.39215686,  0.42745098,  0.32941176],\n",
       "         [ 0.47843137,  0.49411765,  0.42745098],\n",
       "         [ 0.34117647,  0.34117647,  0.29803922],\n",
       "         ..., \n",
       "         [ 0.29411765,  0.30588235,  0.27058824],\n",
       "         [ 0.2745098 ,  0.28627451,  0.25098039],\n",
       "         [ 0.2745098 ,  0.28627451,  0.25098039]],\n",
       "\n",
       "        [[ 0.3372549 ,  0.38823529,  0.27843137],\n",
       "         [ 0.29803922,  0.32941176,  0.25882353],\n",
       "         [ 0.23529412,  0.25098039,  0.21176471],\n",
       "         ..., \n",
       "         [ 0.30588235,  0.31764706,  0.28235294],\n",
       "         [ 0.29803922,  0.30980392,  0.2745098 ],\n",
       "         [ 0.32156863,  0.33333333,  0.29803922]],\n",
       "\n",
       "        [[ 0.32941176,  0.39215686,  0.28627451],\n",
       "         [ 0.3254902 ,  0.37254902,  0.29411765],\n",
       "         [ 0.30196078,  0.3372549 ,  0.28235294],\n",
       "         ..., \n",
       "         [ 0.29019608,  0.30196078,  0.26666667],\n",
       "         [ 0.28627451,  0.29803922,  0.2627451 ],\n",
       "         [ 0.3254902 ,  0.3372549 ,  0.30196078]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.25098039,  0.30196078,  0.30980392],\n",
       "         [ 0.47843137,  0.52156863,  0.56470588],\n",
       "         [ 0.5254902 ,  0.56862745,  0.61176471],\n",
       "         ..., \n",
       "         [ 0.41176471,  0.48235294,  0.47058824],\n",
       "         [ 0.32941176,  0.40392157,  0.35686275],\n",
       "         [ 0.23529412,  0.34509804,  0.24705882]],\n",
       "\n",
       "        [[ 0.17254902,  0.2       ,  0.21960784],\n",
       "         [ 0.30588235,  0.32941176,  0.36862745],\n",
       "         [ 0.37647059,  0.39607843,  0.43137255],\n",
       "         ..., \n",
       "         [ 0.57647059,  0.64705882,  0.69803922],\n",
       "         [ 0.49411765,  0.56078431,  0.58431373],\n",
       "         [ 0.36862745,  0.45882353,  0.44313725]],\n",
       "\n",
       "        [[ 0.14117647,  0.1372549 ,  0.15294118],\n",
       "         [ 0.23137255,  0.22745098,  0.25882353],\n",
       "         [ 0.32156863,  0.31764706,  0.33333333],\n",
       "         ..., \n",
       "         [ 0.5254902 ,  0.6       ,  0.62745098],\n",
       "         [ 0.54117647,  0.59607843,  0.61960784],\n",
       "         [ 0.50980392,  0.58039216,  0.58823529]]],\n",
       "\n",
       "\n",
       "       [[[ 0.0745098 ,  0.1254902 ,  0.05882353],\n",
       "         [ 0.08235294,  0.14901961,  0.08235294],\n",
       "         [ 0.10588235,  0.19215686,  0.1254902 ],\n",
       "         ..., \n",
       "         [ 0.29411765,  0.48627451,  0.51372549],\n",
       "         [ 0.29803922,  0.48627451,  0.50980392],\n",
       "         [ 0.27843137,  0.4627451 ,  0.48627451]],\n",
       "\n",
       "        [[ 0.09019608,  0.12156863,  0.05490196],\n",
       "         [ 0.08235294,  0.11764706,  0.04705882],\n",
       "         [ 0.09019608,  0.1372549 ,  0.05490196],\n",
       "         ..., \n",
       "         [ 0.28235294,  0.4627451 ,  0.49411765],\n",
       "         [ 0.29411765,  0.46666667,  0.48627451],\n",
       "         [ 0.26666667,  0.43529412,  0.44705882]],\n",
       "\n",
       "        [[ 0.09411765,  0.14509804,  0.06666667],\n",
       "         [ 0.08627451,  0.1372549 ,  0.0627451 ],\n",
       "         [ 0.09411765,  0.14117647,  0.07058824],\n",
       "         ..., \n",
       "         [ 0.25098039,  0.42745098,  0.43921569],\n",
       "         [ 0.2627451 ,  0.42745098,  0.43529412],\n",
       "         [ 0.25098039,  0.41176471,  0.41176471]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.24313725,  0.18039216,  0.09019608],\n",
       "         [ 0.23529412,  0.18039216,  0.10588235],\n",
       "         [ 0.21568627,  0.18823529,  0.10980392],\n",
       "         ..., \n",
       "         [ 0.05098039,  0.02352941,  0.01568627],\n",
       "         [ 0.04705882,  0.05490196,  0.03137255],\n",
       "         [ 0.09803922,  0.15686275,  0.11764706]],\n",
       "\n",
       "        [[ 0.24705882,  0.20784314,  0.11764706],\n",
       "         [ 0.19215686,  0.17647059,  0.08627451],\n",
       "         [ 0.17647059,  0.18039216,  0.09019608],\n",
       "         ..., \n",
       "         [ 0.11372549,  0.1372549 ,  0.12156863],\n",
       "         [ 0.11764706,  0.16470588,  0.14509804],\n",
       "         [ 0.10588235,  0.19607843,  0.16862745]],\n",
       "\n",
       "        [[ 0.27058824,  0.20392157,  0.11372549],\n",
       "         [ 0.19215686,  0.14901961,  0.07843137],\n",
       "         [ 0.21176471,  0.18039216,  0.10588235],\n",
       "         ..., \n",
       "         [ 0.25882353,  0.34509804,  0.33333333],\n",
       "         [ 0.15686275,  0.26666667,  0.25098039],\n",
       "         [ 0.11372549,  0.24313725,  0.22745098]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 0.1372549 ,  0.69803922,  0.92156863],\n",
       "         [ 0.15686275,  0.69019608,  0.9372549 ],\n",
       "         [ 0.16470588,  0.69019608,  0.94509804],\n",
       "         ..., \n",
       "         [ 0.38823529,  0.69411765,  0.85882353],\n",
       "         [ 0.30980392,  0.57647059,  0.77254902],\n",
       "         [ 0.34901961,  0.58039216,  0.74117647]],\n",
       "\n",
       "        [[ 0.22352941,  0.71372549,  0.91764706],\n",
       "         [ 0.17254902,  0.72156863,  0.98039216],\n",
       "         [ 0.19607843,  0.71764706,  0.94117647],\n",
       "         ..., \n",
       "         [ 0.61176471,  0.71372549,  0.78431373],\n",
       "         [ 0.55294118,  0.69411765,  0.80784314],\n",
       "         [ 0.45490196,  0.58431373,  0.68627451]],\n",
       "\n",
       "        [[ 0.38431373,  0.77254902,  0.92941176],\n",
       "         [ 0.25098039,  0.74117647,  0.98823529],\n",
       "         [ 0.27058824,  0.75294118,  0.96078431],\n",
       "         ..., \n",
       "         [ 0.7372549 ,  0.76470588,  0.80784314],\n",
       "         [ 0.46666667,  0.52941176,  0.57647059],\n",
       "         [ 0.23921569,  0.30980392,  0.35294118]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.28627451,  0.30980392,  0.30196078],\n",
       "         [ 0.20784314,  0.24705882,  0.26666667],\n",
       "         [ 0.21176471,  0.26666667,  0.31372549],\n",
       "         ..., \n",
       "         [ 0.06666667,  0.15686275,  0.25098039],\n",
       "         [ 0.08235294,  0.14117647,  0.2       ],\n",
       "         [ 0.12941176,  0.18823529,  0.19215686]],\n",
       "\n",
       "        [[ 0.23921569,  0.26666667,  0.29411765],\n",
       "         [ 0.21568627,  0.2745098 ,  0.3372549 ],\n",
       "         [ 0.22352941,  0.30980392,  0.40392157],\n",
       "         ..., \n",
       "         [ 0.09411765,  0.18823529,  0.28235294],\n",
       "         [ 0.06666667,  0.1372549 ,  0.20784314],\n",
       "         [ 0.02745098,  0.09019608,  0.1254902 ]],\n",
       "\n",
       "        [[ 0.17254902,  0.21960784,  0.28627451],\n",
       "         [ 0.18039216,  0.25882353,  0.34509804],\n",
       "         [ 0.19215686,  0.30196078,  0.41176471],\n",
       "         ..., \n",
       "         [ 0.10588235,  0.20392157,  0.30196078],\n",
       "         [ 0.08235294,  0.16862745,  0.25882353],\n",
       "         [ 0.04705882,  0.12156863,  0.19607843]]],\n",
       "\n",
       "\n",
       "       [[[ 0.74117647,  0.82745098,  0.94117647],\n",
       "         [ 0.72941176,  0.81568627,  0.9254902 ],\n",
       "         [ 0.7254902 ,  0.81176471,  0.92156863],\n",
       "         ..., \n",
       "         [ 0.68627451,  0.76470588,  0.87843137],\n",
       "         [ 0.6745098 ,  0.76078431,  0.87058824],\n",
       "         [ 0.6627451 ,  0.76078431,  0.8627451 ]],\n",
       "\n",
       "        [[ 0.76078431,  0.82352941,  0.9372549 ],\n",
       "         [ 0.74901961,  0.81176471,  0.9254902 ],\n",
       "         [ 0.74509804,  0.80784314,  0.92156863],\n",
       "         ..., \n",
       "         [ 0.67843137,  0.75294118,  0.8627451 ],\n",
       "         [ 0.67058824,  0.74901961,  0.85490196],\n",
       "         [ 0.65490196,  0.74509804,  0.84705882]],\n",
       "\n",
       "        [[ 0.81568627,  0.85882353,  0.95686275],\n",
       "         [ 0.80392157,  0.84705882,  0.94117647],\n",
       "         [ 0.8       ,  0.84313725,  0.9372549 ],\n",
       "         ..., \n",
       "         [ 0.68627451,  0.74901961,  0.85098039],\n",
       "         [ 0.6745098 ,  0.74509804,  0.84705882],\n",
       "         [ 0.6627451 ,  0.74901961,  0.84313725]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.81176471,  0.78039216,  0.70980392],\n",
       "         [ 0.79607843,  0.76470588,  0.68627451],\n",
       "         [ 0.79607843,  0.76862745,  0.67843137],\n",
       "         ..., \n",
       "         [ 0.52941176,  0.51764706,  0.49803922],\n",
       "         [ 0.63529412,  0.61960784,  0.58823529],\n",
       "         [ 0.65882353,  0.63921569,  0.59215686]],\n",
       "\n",
       "        [[ 0.77647059,  0.74509804,  0.66666667],\n",
       "         [ 0.74117647,  0.70980392,  0.62352941],\n",
       "         [ 0.70588235,  0.6745098 ,  0.57647059],\n",
       "         ..., \n",
       "         [ 0.69803922,  0.67058824,  0.62745098],\n",
       "         [ 0.68627451,  0.6627451 ,  0.61176471],\n",
       "         [ 0.68627451,  0.6627451 ,  0.60392157]],\n",
       "\n",
       "        [[ 0.77647059,  0.74117647,  0.67843137],\n",
       "         [ 0.74117647,  0.70980392,  0.63529412],\n",
       "         [ 0.69803922,  0.66666667,  0.58431373],\n",
       "         ..., \n",
       "         [ 0.76470588,  0.72156863,  0.6627451 ],\n",
       "         [ 0.76862745,  0.74117647,  0.67058824],\n",
       "         [ 0.76470588,  0.74509804,  0.67058824]]],\n",
       "\n",
       "\n",
       "       [[[ 0.89803922,  0.89803922,  0.9372549 ],\n",
       "         [ 0.9254902 ,  0.92941176,  0.96862745],\n",
       "         [ 0.91764706,  0.9254902 ,  0.96862745],\n",
       "         ..., \n",
       "         [ 0.85098039,  0.85882353,  0.91372549],\n",
       "         [ 0.86666667,  0.8745098 ,  0.91764706],\n",
       "         [ 0.87058824,  0.8745098 ,  0.91372549]],\n",
       "\n",
       "        [[ 0.87058824,  0.86666667,  0.89803922],\n",
       "         [ 0.9372549 ,  0.9372549 ,  0.97647059],\n",
       "         [ 0.91372549,  0.91764706,  0.96470588],\n",
       "         ..., \n",
       "         [ 0.8745098 ,  0.8745098 ,  0.9254902 ],\n",
       "         [ 0.89019608,  0.89411765,  0.93333333],\n",
       "         [ 0.82352941,  0.82745098,  0.8627451 ]],\n",
       "\n",
       "        [[ 0.83529412,  0.80784314,  0.82745098],\n",
       "         [ 0.91764706,  0.90980392,  0.9372549 ],\n",
       "         [ 0.90588235,  0.91372549,  0.95686275],\n",
       "         ..., \n",
       "         [ 0.8627451 ,  0.8627451 ,  0.90980392],\n",
       "         [ 0.8627451 ,  0.85882353,  0.90980392],\n",
       "         [ 0.79215686,  0.79607843,  0.84313725]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.58823529,  0.56078431,  0.52941176],\n",
       "         [ 0.54901961,  0.52941176,  0.49803922],\n",
       "         [ 0.51764706,  0.49803922,  0.47058824],\n",
       "         ..., \n",
       "         [ 0.87843137,  0.87058824,  0.85490196],\n",
       "         [ 0.90196078,  0.89411765,  0.88235294],\n",
       "         [ 0.94509804,  0.94509804,  0.93333333]],\n",
       "\n",
       "        [[ 0.5372549 ,  0.51764706,  0.49411765],\n",
       "         [ 0.50980392,  0.49803922,  0.47058824],\n",
       "         [ 0.49019608,  0.4745098 ,  0.45098039],\n",
       "         ..., \n",
       "         [ 0.70980392,  0.70588235,  0.69803922],\n",
       "         [ 0.79215686,  0.78823529,  0.77647059],\n",
       "         [ 0.83137255,  0.82745098,  0.81176471]],\n",
       "\n",
       "        [[ 0.47843137,  0.46666667,  0.44705882],\n",
       "         [ 0.4627451 ,  0.45490196,  0.43137255],\n",
       "         [ 0.47058824,  0.45490196,  0.43529412],\n",
       "         ..., \n",
       "         [ 0.70196078,  0.69411765,  0.67843137],\n",
       "         [ 0.64313725,  0.64313725,  0.63529412],\n",
       "         [ 0.63921569,  0.63921569,  0.63137255]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(valid_labels)\n",
    "valid_labels.shape\n",
    "valid_features.shape\n",
    "valid_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, (32, 32, 3)]\n",
      "Image Input Tests Passed.\n",
      "[None, 10]\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print([None,image_shape])\n",
    "    return tf.placeholder(tf.float32, [None,image_shape[0], image_shape[1], image_shape[2]],name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print([None,n_classes])\n",
    "    return tf.placeholder(tf.float32, [None,n_classes],name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "<tf.Variable 'Variable:0' shape=(2, 2, 5, 10) dtype=float32_ref>\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #dim = x_tensor.get_shape().as_list()\n",
    "    #print(dim[-1])\n",
    "    #shape = list(conv_ksize+(dim[-1],)+(conv_num_outputs,))  \n",
    "    #print(shape)\n",
    "    weight = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_tensor.get_shape().as_list()[-1], conv_num_outputs], stddev=0.05))\n",
    "    print(x_tensor.get_shape().as_list()[-1])\n",
    "    print(x_tensor.get_shape().as_list()[3])\n",
    "    print(weight)\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conv_layer = tf.nn.conv2d(x_tensor,weight,strides=[1,conv_strides[0],conv_strides[1],1],padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer,bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    conv_layer = tf.nn.max_pool(conv_layer,ksize=[1,pool_ksize[0],pool_ksize[1],1],strides=[1,pool_strides[0],pool_strides[1],1],padding='SAME')\n",
    "    return conv_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "#from numpy import prod\n",
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #shape = x_tensor.get_shape().as_list()\n",
    "    #print(shape)\n",
    "    #dim = x_tensor.get_shape().as_list()    \n",
    "    #return tf.reshape(x_tensor,[-1,prod(dim[1:])])\n",
    "    #return tf.contrib.layers.flatten(x_tensor)\n",
    "    return tf.reshape(x_tensor, [-1, x_tensor.shape.as_list()[1] * x_tensor.shape.as_list()[2] * x_tensor.shape.as_list()[3] ] ) \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "[128, 40]\n",
      "<tf.Variable 'Variable_2:0' shape=(128, 40) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_3:0' shape=(40,) dtype=float32_ref>\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #fc_layer = tf.contrib.layers.fully_connected(x_tensor,num_outputs,activation_fn=tf.nn.relu)\n",
    "    #return fc_layer\n",
    "    dim = x_tensor.get_shape().as_list()\n",
    "    print(num_outputs)\n",
    "    shape = list( (dim[-1],) + (num_outputs,))\n",
    "    print(shape)\n",
    "    weight = tf.Variable(tf.truncated_normal(shape,0,0.05))\n",
    "    print(weight)\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    print(bias)\n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor,weight), bias))\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 40]\n",
      "<tf.Variable 'Variable_24:0' shape=(128, 40) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_25:0' shape=(40,) dtype=float32_ref>\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dim = x_tensor.get_shape().as_list()\n",
    "    shape =  list((dim[-1],)+(num_outputs,))\n",
    "    print(shape)\n",
    "    #weight = tf.truncated_normal(shape,0,0.05)\n",
    "    weight = tf.Variable(tf.truncated_normal(shape,0,0.05))\n",
    "    print(weight)\n",
    "    #bias = tf.zeros(num_outputs)\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    print(bias)\n",
    "    return tf.add(tf.matmul(x_tensor,weight),bias)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, (32, 32, 3)]\n",
      "[None, 10]\n",
      "3\n",
      "3\n",
      "<tf.Variable 'Variable:0' shape=(5, 5, 3, 20) dtype=float32_ref>\n",
      "512\n",
      "[20480, 512]\n",
      "<tf.Variable 'Variable_2:0' shape=(20480, 512) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_3:0' shape=(512,) dtype=float32_ref>\n",
      "256\n",
      "[512, 256]\n",
      "<tf.Variable 'Variable_4:0' shape=(512, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_5:0' shape=(256,) dtype=float32_ref>\n",
      "128\n",
      "[256, 128]\n",
      "<tf.Variable 'Variable_6:0' shape=(256, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_7:0' shape=(128,) dtype=float32_ref>\n",
      "[128, 10]\n",
      "<tf.Variable 'Variable_8:0' shape=(128, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_9:0' shape=(10,) dtype=float32_ref>\n",
      "Tensor(\"Add_3:0\", shape=(?, 10), dtype=float32)\n",
      "3\n",
      "3\n",
      "<tf.Variable 'Variable_10:0' shape=(5, 5, 3, 20) dtype=float32_ref>\n",
      "512\n",
      "[20480, 512]\n",
      "<tf.Variable 'Variable_12:0' shape=(20480, 512) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_13:0' shape=(512,) dtype=float32_ref>\n",
      "256\n",
      "[512, 256]\n",
      "<tf.Variable 'Variable_14:0' shape=(512, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_15:0' shape=(256,) dtype=float32_ref>\n",
      "128\n",
      "[256, 128]\n",
      "<tf.Variable 'Variable_16:0' shape=(256, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_17:0' shape=(128,) dtype=float32_ref>\n",
      "[128, 10]\n",
      "<tf.Variable 'Variable_18:0' shape=(128, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_19:0' shape=(10,) dtype=float32_ref>\n",
      "Tensor(\"Add_7:0\", shape=(?, 10), dtype=float32)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    #conv1 = conv2d_maxpool(x, conv_num_outputs=12, conv_ksize=(3,3), conv_strides=(1,1), pool_ksize=(2,2), pool_strides=(1,1))\n",
    "    conv2 = conv2d_maxpool(x, conv_num_outputs=20, conv_ksize=(5,5), conv_strides=(1,1), pool_ksize=(2,2), pool_strides=(1,1))\n",
    "    #convl = tf.nn.dropout(conv1,keep_prob)\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    conv3 = flatten(conv2)\n",
    "    #conv3 = tf.nn.dropout(conv3,keep_prob)\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    #model = fully_conn(model, 20)\n",
    "    #fc3 = fully_conn(conv3, 384)\n",
    "    fc1 = fully_conn(conv3, 512)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    fc2 = fully_conn(fc1,256)\n",
    "    fc2 = tf.nn.dropout(fc2,keep_prob)\n",
    "    fc3 = fully_conn(fc2, 128)\n",
    "    fc3 = tf.nn.dropout(fc3, keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)tf.nn.dropout(hidden_layer, keep_prob)\n",
    "    model = output(fc3, 10)\n",
    "    conv = tf.nn.dropout(model, keep_prob)\n",
    "    print(model)\n",
    "    # TODO: return output\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # pass\n",
    "    #init = tf.global_variables_initializer()\n",
    "    #session.run(init)\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.0})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                loss,\n",
    "                valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "keep_probability = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## \"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1360 Validation Accuracy: 0.282000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.8922 Validation Accuracy: 0.367800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.6325 Validation Accuracy: 0.388800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.3650 Validation Accuracy: 0.422200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.1327 Validation Accuracy: 0.449800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     0.9655 Validation Accuracy: 0.469800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.8246 Validation Accuracy: 0.483400\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.7276 Validation Accuracy: 0.484600\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.6181 Validation Accuracy: 0.495800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.5012 Validation Accuracy: 0.499600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.3921 Validation Accuracy: 0.492800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.3139 Validation Accuracy: 0.525200\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.2798 Validation Accuracy: 0.510600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.2167 Validation Accuracy: 0.527600\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.1684 Validation Accuracy: 0.507200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.1395 Validation Accuracy: 0.524000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.1149 Validation Accuracy: 0.520800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.1405 Validation Accuracy: 0.496400\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.0941 Validation Accuracy: 0.524400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.0668 Validation Accuracy: 0.528000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.0465 Validation Accuracy: 0.528200\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.0573 Validation Accuracy: 0.522600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.0302 Validation Accuracy: 0.528600\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.1065 Validation Accuracy: 0.527200\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.0272 Validation Accuracy: 0.536000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.0294 Validation Accuracy: 0.532200\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.0128 Validation Accuracy: 0.531200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.0139 Validation Accuracy: 0.521800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.0091 Validation Accuracy: 0.535600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.0045 Validation Accuracy: 0.525600\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.0060 Validation Accuracy: 0.528000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.0050 Validation Accuracy: 0.523400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.0035 Validation Accuracy: 0.541600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.0050 Validation Accuracy: 0.530200\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.0024 Validation Accuracy: 0.539000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.0008 Validation Accuracy: 0.526600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.0021 Validation Accuracy: 0.530200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.0007 Validation Accuracy: 0.527000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.0013 Validation Accuracy: 0.531400\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.0009 Validation Accuracy: 0.532600\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.0012 Validation Accuracy: 0.535800\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.0016 Validation Accuracy: 0.533200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.0010 Validation Accuracy: 0.534800\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.0008 Validation Accuracy: 0.537600\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.0006 Validation Accuracy: 0.549400\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.0005 Validation Accuracy: 0.533600\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.0006 Validation Accuracy: 0.538800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.0005 Validation Accuracy: 0.520000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.0004 Validation Accuracy: 0.528800\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.0003 Validation Accuracy: 0.530200\n"
     ]
    }
   ],
   "source": [
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.0880 Validation Accuracy: 0.259200\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.7018 Validation Accuracy: 0.376400\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.5064 Validation Accuracy: 0.407400\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.4933 Validation Accuracy: 0.448800\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.4502 Validation Accuracy: 0.436800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.4744 Validation Accuracy: 0.483600\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.1235 Validation Accuracy: 0.485400\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     0.9725 Validation Accuracy: 0.503800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.2311 Validation Accuracy: 0.521600\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     0.9897 Validation Accuracy: 0.530000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.0360 Validation Accuracy: 0.539400\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     0.8047 Validation Accuracy: 0.516600\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     0.8095 Validation Accuracy: 0.538200\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.0769 Validation Accuracy: 0.530800\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     0.7340 Validation Accuracy: 0.538200\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     0.7685 Validation Accuracy: 0.571000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     0.7501 Validation Accuracy: 0.581200\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.5699 Validation Accuracy: 0.581400\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     0.7971 Validation Accuracy: 0.576600\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     0.5476 Validation Accuracy: 0.568200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     0.5407 Validation Accuracy: 0.570400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     0.5187 Validation Accuracy: 0.599200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.4838 Validation Accuracy: 0.591000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.5209 Validation Accuracy: 0.612600\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     0.4083 Validation Accuracy: 0.600400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     0.4563 Validation Accuracy: 0.597400\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.4123 Validation Accuracy: 0.605200\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.3285 Validation Accuracy: 0.616800\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.3448 Validation Accuracy: 0.632400\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.3239 Validation Accuracy: 0.617800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.3516 Validation Accuracy: 0.610000\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.3532 Validation Accuracy: 0.614000\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.2864 Validation Accuracy: 0.610800\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.2825 Validation Accuracy: 0.627800\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.2180 Validation Accuracy: 0.631800\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.3292 Validation Accuracy: 0.620600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.2526 Validation Accuracy: 0.631400\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.2166 Validation Accuracy: 0.629600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.2059 Validation Accuracy: 0.634400\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.1787 Validation Accuracy: 0.620800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.2465 Validation Accuracy: 0.620400\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.2296 Validation Accuracy: 0.640000\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.1843 Validation Accuracy: 0.626200\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.1700 Validation Accuracy: 0.639800\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.1367 Validation Accuracy: 0.627200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.1758 Validation Accuracy: 0.638000\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.1941 Validation Accuracy: 0.645400\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.1421 Validation Accuracy: 0.627600\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.1385 Validation Accuracy: 0.642400\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.0848 Validation Accuracy: 0.646800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.1198 Validation Accuracy: 0.633400\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     0.1227 Validation Accuracy: 0.635600\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     0.1060 Validation Accuracy: 0.645000\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     0.1083 Validation Accuracy: 0.624800\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     0.0670 Validation Accuracy: 0.641000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.1026 Validation Accuracy: 0.643400\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     0.0958 Validation Accuracy: 0.635600\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     0.0884 Validation Accuracy: 0.628800\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     0.0705 Validation Accuracy: 0.634600\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     0.0706 Validation Accuracy: 0.649200\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.0806 Validation Accuracy: 0.644800\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     0.0979 Validation Accuracy: 0.645200\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     0.0705 Validation Accuracy: 0.653400\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     0.0772 Validation Accuracy: 0.626200\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     0.0577 Validation Accuracy: 0.646600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.0693 Validation Accuracy: 0.631000\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     0.0791 Validation Accuracy: 0.634800\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     0.0591 Validation Accuracy: 0.653000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     0.0482 Validation Accuracy: 0.644000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     0.0495 Validation Accuracy: 0.654000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.0551 Validation Accuracy: 0.638600\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     0.0795 Validation Accuracy: 0.638800\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     0.0630 Validation Accuracy: 0.652600\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     0.0532 Validation Accuracy: 0.637400\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     0.0326 Validation Accuracy: 0.653400\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.0749 Validation Accuracy: 0.635200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     0.0659 Validation Accuracy: 0.624200\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     0.0577 Validation Accuracy: 0.645600\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.0393 Validation Accuracy: 0.632400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.0368 Validation Accuracy: 0.647600\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.0338 Validation Accuracy: 0.633200\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     0.0425 Validation Accuracy: 0.625000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     0.0402 Validation Accuracy: 0.641600\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.0285 Validation Accuracy: 0.637800\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.0238 Validation Accuracy: 0.643400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.0419 Validation Accuracy: 0.651200\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     0.0412 Validation Accuracy: 0.619400\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.0236 Validation Accuracy: 0.642400\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.0156 Validation Accuracy: 0.640200\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.0154 Validation Accuracy: 0.651000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.0251 Validation Accuracy: 0.646600\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     0.0218 Validation Accuracy: 0.617800\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.0196 Validation Accuracy: 0.652200\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.0142 Validation Accuracy: 0.639600\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.0187 Validation Accuracy: 0.642200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.0247 Validation Accuracy: 0.639000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     0.0204 Validation Accuracy: 0.632800\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.0129 Validation Accuracy: 0.645000\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.0090 Validation Accuracy: 0.632400\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.0144 Validation Accuracy: 0.642200\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.0208 Validation Accuracy: 0.634800\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     0.0160 Validation Accuracy: 0.641800\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     0.0171 Validation Accuracy: 0.641000\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     0.0080 Validation Accuracy: 0.639200\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     0.0103 Validation Accuracy: 0.635600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.0130 Validation Accuracy: 0.631600\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     0.0099 Validation Accuracy: 0.651800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     0.0175 Validation Accuracy: 0.646800\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     0.0165 Validation Accuracy: 0.645400\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     0.0063 Validation Accuracy: 0.647400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.0124 Validation Accuracy: 0.647800\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     0.0150 Validation Accuracy: 0.639800\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     0.0110 Validation Accuracy: 0.649800\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     0.0083 Validation Accuracy: 0.637400\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     0.0058 Validation Accuracy: 0.647400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.0108 Validation Accuracy: 0.634600\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.0045 Validation Accuracy: 0.631600\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     0.0120 Validation Accuracy: 0.639000\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     0.0088 Validation Accuracy: 0.645800\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     0.0088 Validation Accuracy: 0.657800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.0091 Validation Accuracy: 0.639600\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.0062 Validation Accuracy: 0.634000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.0039 Validation Accuracy: 0.649000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     0.0046 Validation Accuracy: 0.654400\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     0.0078 Validation Accuracy: 0.649800\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.0058 Validation Accuracy: 0.620200\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.0062 Validation Accuracy: 0.643600\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.0062 Validation Accuracy: 0.654800\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     0.0025 Validation Accuracy: 0.650000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     0.0053 Validation Accuracy: 0.653600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.0058 Validation Accuracy: 0.640400\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.0055 Validation Accuracy: 0.636000\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.0031 Validation Accuracy: 0.656600\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     0.0021 Validation Accuracy: 0.650400\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.0027 Validation Accuracy: 0.660600\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.0030 Validation Accuracy: 0.636200\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.0034 Validation Accuracy: 0.632600\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.0029 Validation Accuracy: 0.652000\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     0.0010 Validation Accuracy: 0.655600\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.0026 Validation Accuracy: 0.650200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.0032 Validation Accuracy: 0.636600\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.0017 Validation Accuracy: 0.611200\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.0031 Validation Accuracy: 0.647400\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.0013 Validation Accuracy: 0.648800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.0069 Validation Accuracy: 0.650200\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.0024 Validation Accuracy: 0.631400\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.0025 Validation Accuracy: 0.623000\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.0043 Validation Accuracy: 0.644800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.0011 Validation Accuracy: 0.647600\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.0022 Validation Accuracy: 0.645000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.0023 Validation Accuracy: 0.635400\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     0.0010 Validation Accuracy: 0.622400\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.0023 Validation Accuracy: 0.648000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     0.0025 Validation Accuracy: 0.641000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     0.0015 Validation Accuracy: 0.642000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.0030 Validation Accuracy: 0.643200\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.0171 Validation Accuracy: 0.627000\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.0030 Validation Accuracy: 0.649800\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     0.0022 Validation Accuracy: 0.655600\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     0.0012 Validation Accuracy: 0.647600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.0022 Validation Accuracy: 0.639600\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.0052 Validation Accuracy: 0.639400\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.0020 Validation Accuracy: 0.646400\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     0.0051 Validation Accuracy: 0.638400\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     0.0008 Validation Accuracy: 0.660000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.0027 Validation Accuracy: 0.647400\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.0010 Validation Accuracy: 0.639000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.0053 Validation Accuracy: 0.652200\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     0.0014 Validation Accuracy: 0.646400\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     0.0006 Validation Accuracy: 0.650000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.0014 Validation Accuracy: 0.642800\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.0006 Validation Accuracy: 0.635600\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.0007 Validation Accuracy: 0.658400\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     0.0015 Validation Accuracy: 0.649800\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     0.0011 Validation Accuracy: 0.647800\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.0010 Validation Accuracy: 0.643600\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.0021 Validation Accuracy: 0.622400\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.0020 Validation Accuracy: 0.647400\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     0.0015 Validation Accuracy: 0.644400\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     0.0009 Validation Accuracy: 0.650600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.0021 Validation Accuracy: 0.646400\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.0009 Validation Accuracy: 0.627000\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.0007 Validation Accuracy: 0.649800\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     0.0016 Validation Accuracy: 0.649800\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     0.0005 Validation Accuracy: 0.656200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.0017 Validation Accuracy: 0.641200\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.0008 Validation Accuracy: 0.637400\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.0010 Validation Accuracy: 0.651000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     0.0113 Validation Accuracy: 0.646800\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     0.0003 Validation Accuracy: 0.647600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.0010 Validation Accuracy: 0.636200\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.0017 Validation Accuracy: 0.639000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.0016 Validation Accuracy: 0.652000\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     0.0030 Validation Accuracy: 0.645400\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     0.0007 Validation Accuracy: 0.647600\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.642800\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.0020 Validation Accuracy: 0.634800\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.0013 Validation Accuracy: 0.649000\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     0.0005 Validation Accuracy: 0.647000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     0.0004 Validation Accuracy: 0.656000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.0020 Validation Accuracy: 0.636200\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.0004 Validation Accuracy: 0.641200\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.0009 Validation Accuracy: 0.648800\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     0.0005 Validation Accuracy: 0.651600\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     0.0002 Validation Accuracy: 0.646400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.641200\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.0006 Validation Accuracy: 0.631600\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.0004 Validation Accuracy: 0.649200\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     0.0003 Validation Accuracy: 0.644800\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     0.0006 Validation Accuracy: 0.644000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.0013 Validation Accuracy: 0.646000\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.0019 Validation Accuracy: 0.644000\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.0006 Validation Accuracy: 0.643400\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     0.0002 Validation Accuracy: 0.648200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     0.0004 Validation Accuracy: 0.657200\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.644400\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.0003 Validation Accuracy: 0.638000\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.0006 Validation Accuracy: 0.647800\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     0.0001 Validation Accuracy: 0.646600\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     0.0004 Validation Accuracy: 0.652200\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.0004 Validation Accuracy: 0.651800\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.0008 Validation Accuracy: 0.635800\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.0008 Validation Accuracy: 0.647400\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     0.0001 Validation Accuracy: 0.653800\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     0.0005 Validation Accuracy: 0.652400\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.0007 Validation Accuracy: 0.656600\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.0003 Validation Accuracy: 0.649000\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.0002 Validation Accuracy: 0.647000\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     0.0004 Validation Accuracy: 0.638800\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     0.0003 Validation Accuracy: 0.657400\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.0005 Validation Accuracy: 0.652400\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.0015 Validation Accuracy: 0.642400\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.0016 Validation Accuracy: 0.641200\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     0.0002 Validation Accuracy: 0.648600\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     0.0001 Validation Accuracy: 0.662000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.652000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.0004 Validation Accuracy: 0.646400\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.0004 Validation Accuracy: 0.652800\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     0.0006 Validation Accuracy: 0.651400\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     0.0001 Validation Accuracy: 0.651600\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.0005 Validation Accuracy: 0.658800\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.0002 Validation Accuracy: 0.650400\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.0003 Validation Accuracy: 0.644800\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     0.0002 Validation Accuracy: 0.652800\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     0.0001 Validation Accuracy: 0.653600\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.0003 Validation Accuracy: 0.656200\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.0024 Validation Accuracy: 0.637400\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.0009 Validation Accuracy: 0.639200\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     0.0002 Validation Accuracy: 0.648600\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     0.0003 Validation Accuracy: 0.651600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6357421875\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24f45a7ca90>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
